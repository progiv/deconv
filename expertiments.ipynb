{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка линейного искажающего оператора в задаче восстановления изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d as conv2\n",
    "\n",
    "from skimage import color, data, restoration, io, img_as_float\n",
    "from skimage.restoration import uft\n",
    "from scipy.signal import fftconvolve, convolve, convolve2d\n",
    "from scipy.stats.stats import pearsonr\n",
    "from numpy.fft import fftn, ifftn\n",
    "from skimage.measure import compare_psnr\n",
    "from skimage.draw import bezier_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interactive graphics\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "sz = 11\n",
    "astro = color.rgb2gray(data.astronaut())\n",
    "\n",
    "psf = np.ones((sz, sz)) / (sz*sz)\n",
    "astro_noisy = conv2(astro, psf, 'same')\n",
    "# Add Noise to Image\n",
    "#astro_noisy += (np.random.poisson(lam=25, size=astro.shape) - 10) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(original, noisy, result, titles=['Original Data', 'Blurred data', 'Restoration using\\nRichardson-Lucy']):\n",
    "    # Show results\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(12, 10))\n",
    "    plt.gray()\n",
    "\n",
    "    for a in (ax[0], ax[1], ax[2]):\n",
    "           a.axis('off')\n",
    "\n",
    "    ax[0].imshow(original, vmin=0, vmax=1)\n",
    "    ax[0].set_title(titles[0])\n",
    "\n",
    "    ax[1].imshow(noisy, vmin=0, vmax=1)\n",
    "    ax[1].set_title(titles[1])\n",
    "\n",
    "    ax[2].imshow(result, vmin=0, vmax=1)\n",
    "    ax[2].set_title(titles[2])\n",
    "\n",
    "\n",
    "    fig.subplots_adjust(wspace=0.02, hspace=0.2,\n",
    "                        top=0.9, bottom=0.05, left=0, right=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_correlation(image):\n",
    "    return pearsonr(image[1:,:].ravel(), image[:-1,:].ravel())[0]\n",
    "    \n",
    "def col_correlation(image):\n",
    "    return pearsonr(image[:,1:].ravel(), image[:,:-1].ravel())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desubsample(image, times=1, axises=None):\n",
    "    if axises is None:\n",
    "        axises = [i for i, sz in enumerate(image.shape) if sz > 4]\n",
    "    for axis in axises:\n",
    "        image = image.repeat(times, axis)#, inplace=True)\n",
    "    return image\n",
    "\n",
    "def corelucy(Y, psf, dampar22, wI, readout, subsample, numNSdim, vec, num, eps=1e-9, useFFT=False):\n",
    "    \"\"\"\n",
    "    CORELUCY Accelerated Damped Lucy-Richarson Operator.\n",
    "    Calculates function that when used with the scaled projected array\n",
    "    produces the next iteration array that maximizes the likelihood that\n",
    "    the entire suite satisfies the Poisson statistics.\n",
    "    \"\"\"\n",
    "    if useFFT:\n",
    "        reBlurred = np.real(ifftn(fftn(Y) * psf)) #Here psf=H = fftn(psf)\n",
    "    else:\n",
    "        reBlurred = np.real(convolve2d(Y, psf, 'same'))\n",
    "\n",
    "    # 1. Resampling if needed\n",
    "    if subsample != 1: # Bin reBlurred back to the sizeI for non-singleton dims\n",
    "        #1.Reshape so that the-to-binned dimension separates into two\n",
    "        #dimensions, with one of them consisting of elements of a single bin.\n",
    "        reBlurred = np.reshape(reBlurred, vec);\n",
    "\n",
    "        #2. Bin (==calculate mean) along the first of the-to-binned dimension,\n",
    "        #that dimension consists of the bin elements. Reshape to get rid off\n",
    "        for k in num: # new appeared singleton.\n",
    "            vec.pop(k) #~ vec(k) = [];\n",
    "            reBlurred = reshape(mean(reBlurred,k),vec);\n",
    "\n",
    "    # 2. An Estimate for the next step\n",
    "    reBlurred += readout;\n",
    "    reBlurred[reBlurred <= 0] = eps;\n",
    "    AnEstim = wI / reBlurred + eps;\n",
    "    AnEstim[AnEstim<=0] = eps\n",
    "\n",
    "    # 3. Damping if needed\n",
    "    if dampar22 == 0: # No Damping\n",
    "        ImRatio = desubsample(AnEstim, subsample, numNSdim);\n",
    "    else: # Damping of the image relative to dampar22 = (N*sigma)^2\n",
    "        gm = 10;\n",
    "        g = (wI * np.log(AnEstim)+ reBlurred - wI) / dampar22;\n",
    "        g = np.minimum(g,1);\n",
    "        G = (g**(gm-1))*(gm-(gm-1)*g);\n",
    "        ImRatio = 1 + desubsample(G,subsample, numNSdim) * (desubsample(AnEstim, subsample, numNSdim) - 1);\n",
    "    if useFFT:\n",
    "        return fftn(ImRatio);\n",
    "    else:\n",
    "        return ImRatio\n",
    "\n",
    "def richardson_lucy_matlab(image, psf, iterations=50, dampar=0, weight=None, readout=0, \n",
    "                           subsample=1, eps=1e-16, clip=True, useFFT=False):\n",
    "    \"\"\" Richardson-Lucy deconvolution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : ndarray\n",
    "       Input degraded image (can be N dimensional).\n",
    "    psf : ndarray\n",
    "       The point spread function.\n",
    "    iterations : int\n",
    "       Number of iterations. This parameter plays the role of\n",
    "       regularisation.\n",
    "    \"\"\"\n",
    "    #if 'eps' not in globals():\n",
    "    #    eps = 1e-9\n",
    "    # to continue restoration\n",
    "    sizeI = image.shape\n",
    "    sizePSF = psf.shape\n",
    "    numNSdim = [i for i, sz in enumerate(sizePSF) if sz > 4] # do not desubsample rgb axis\n",
    "    \n",
    "    psf_mirror = psf[::-1, ::-1]\n",
    "\n",
    "    assert(not np.all(psf == 0))\n",
    "\n",
    "    if isinstance(image, list) and len(image) == 4:\n",
    "        image, prev_image, prev_prev_image, internal = image\n",
    "    else:\n",
    "        prev_image = np.ones(image.shape)*.5#image\n",
    "        prev_prev_image = 0\n",
    "        internal = np.zeros((image.size*subsample**len(numNSdim),2))\n",
    "    internal[:,1] = 0\n",
    "\n",
    "    if weight is None:\n",
    "        weight = np.ones(image.shape)\n",
    "\n",
    "    # 1. Prepare OTF\n",
    "    #~ H = psf2otf(psf, sizeI);\n",
    "    if psf.shape != image.shape:\n",
    "        H = uft.ir2tf(psf, image.shape, is_real=False)\n",
    "    else:\n",
    "        H = psf\n",
    "    H_mirror = H[::-1, ::-1]\n",
    "\n",
    "    wI = np.maximum(weight * (readout + image), 0)\n",
    "    prev_image = desubsample(prev_image, subsample, numNSdim)\n",
    "    if useFFT:\n",
    "        scale = np.real(ifftn(np.conj(H)*fftn(desubsample(weight)))) + np.sqrt(eps)\n",
    "    else:\n",
    "        scale = np.real(convolve2d(desubsample(weight), psf_mirror, 'same')) + np.sqrt(eps)\n",
    "    del weight\n",
    "\n",
    "    dampar22 = np.square(dampar)/2\n",
    "\n",
    "    '''\n",
    "    prepare vector of dimensions to facilitate the reshaping\n",
    "    % when the matrix is binned within the iterations.\n",
    "    '''\n",
    "    vec = []\n",
    "    num = []\n",
    "    if subsample != 1:\n",
    "        for dim, sz in enumerate(sizeI):\n",
    "            if sz != 1:\n",
    "                vec.extend((subsample, sz))\n",
    "                num.append(dim)\n",
    "            else:\n",
    "                vec.append(sz)\n",
    "    num.reverse()\n",
    "\n",
    "    # 3 L_R Iterations\n",
    "    lambd = 2 * np.any(internal != 0)\n",
    "    correlation_X = [col_correlation(image)]\n",
    "    correlation_Y = [row_correlation(image)]\n",
    "    for k in range(lambd, lambd + iterations):\n",
    "\n",
    "        # 3.a Make an image predictions for the next iteration\n",
    "        if k > 2:\n",
    "            lambd = (internal[:,0].T.dot(internal[:,1])) / (internal[:,1].T.dot(internal[:,1]) +eps) # (scalar division)\n",
    "            lambd = max(min(lambd, 1), 0) # stability enforcement saturation\n",
    "        Y = np.maximum(prev_image + lambd*(prev_image - prev_prev_image), 0) # plus positivity constraint\n",
    "\n",
    "        # 3.b Make core for the LR estimation\n",
    "        if useFFT:\n",
    "            cc = corelucy(Y, H, dampar22, wI, readout, subsample, numNSdim, vec, num, eps, useFFT)\n",
    "        else:\n",
    "            cc = corelucy(Y, psf, dampar22, wI, readout, subsample, numNSdim, vec, num, eps, useFFT)\n",
    "\n",
    "        # 3.c Determine next iteration image and apply poitivity constraint\n",
    "        prev_prev_image = prev_image\n",
    "        if useFFT:\n",
    "            prev_image = np.maximum(Y * np.real(ifftn(cc * np.conj(H))) / scale, 0)\n",
    "        else:\n",
    "            prev_image = np.maximum(Y * np.real(convolve2d(cc, psf_mirror, 'same')) / scale, 0)\n",
    "        if clip:\n",
    "            prev_image[prev_image > 1] = 1\n",
    "            prev_image[prev_image < eps] = eps\n",
    "        correlation_X.append(col_correlation(prev_image))\n",
    "        correlation_Y.append(row_correlation(prev_image))\n",
    "        del cc\n",
    "        internal[:,1] = internal[:,0]\n",
    "        internal[:,0] = (prev_image-Y).ravel()\n",
    "    del wI, H, scale, Y\n",
    "    return {'image': prev_image, \n",
    "            'correlationX': np.array(correlation_X)/(image.size-1), \n",
    "            'correlationY': np.array(correlation_Y)/(image.size-1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def plot_corr(n, ydata, legend=['row correlation', 'column correlation'], title='Normalized correlation'):\n",
    "    plt.plot(*list(chain(*[(range(n), y) for y in ydata])))\n",
    "    plt.grid()\n",
    "    plt.title(title)\n",
    "    plt.xlabel('n iterations')\n",
    "    plt.legend(legend)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore Image using Richardson-Lucy algorithm:\n",
    "iterations = 20\n",
    "deconv = richardson_lucy_matlab(astro_noisy, psf, iterations=iterations, eps=1e-5)\n",
    "show_results(astro, astro_noisy, deconv['image'])\n",
    "plot_corr(iterations+1, [deconv['correlationX'], \n",
    "                         deconv['correlationY']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liftingbody = img_as_float(io.imread('liftingbody.png'))\n",
    "lifting_blurred = conv2(liftingbody, psf, 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore Image using Richardson-Lucy algorithm my:\n",
    "iterations = 20\n",
    "deconv = richardson_lucy_matlab(lifting_blurred, psf, iterations=iterations, eps=1e-5, useFFT=True)\n",
    "show_results(liftingbody, lifting_blurred, deconv['image'])\n",
    "plot_corr(iterations+1, [deconv['correlationX'], \n",
    "                         deconv['correlationY']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// matlab original for gen psf (curved line shift)\n",
    "```python\n",
    "def gen_psf():\n",
    "    p0 = np.random.randint(6, 25)\n",
    "    p1 = np.random.randint(6, 21)\n",
    "\n",
    "    x = np.random.randint(0, p0, (1,4))#sort(randi([0 p0], 1, 4));\n",
    "    y = np.random.randint(0, p1, (1,4))\n",
    "\n",
    "    pt1 = [x[0]; y[0]]\n",
    "    pt2 = [x[1]; y[1]]\n",
    "    pt3 = [x[2]; y[2]]\n",
    "    pt4 = [x[3]; y[3]]\n",
    "\n",
    "    t = list(range(0, p0+1))\n",
    "    pts = kron((1-t).^3,pt1) + kron(3*(1-t).^2.*t,pt2) + kron(3*(1-t).*t.^2,pt3) + kron(t.^3,pt4);\n",
    "    x1 = 1:p0;\n",
    "    y1 = round(pts(2, :));\n",
    "    y1 = y1 - min(y1) + 1;\n",
    "    %plot(x1,y1);\n",
    "    pp = max(y1);\n",
    "    PSF = zeros(p0, pp);\n",
    "\n",
    "    for ind_x = 1:length(x1)\n",
    "        yy = max(length(x1) - y1(ind_x), 1);\n",
    "        PSF(yy, ind_x) = rand();\n",
    "    end\n",
    "\n",
    "    PSF = PSF./(sum(PSF(:)) + eps*p0*p0);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Криволинейный оператор смаза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curved_psf(points = 3, maxlen = 30):\n",
    "    eps = 1e-16\n",
    "    p0 = np.random.randint(6, maxlen)\n",
    "    p1 = np.random.randint(6, maxlen)\n",
    "\n",
    "    x = np.random.randint(0, p0, points)#sort(randi([0 p0], 1, 4));\n",
    "    y = np.random.randint(0, p1, points)\n",
    "\n",
    "    pt1 = [[0], [0]]#[[x[0]], [y[0]]]\n",
    "    pt2 = [[x[1]], [y[1]]]\n",
    "    pt3 = [[x[2]], [y[2]]]\n",
    "    print('curve', pt1, pt2, pt3)\n",
    "    #pt4 = [[x[3]], [y[3]]]\n",
    "\n",
    "    t = np.linspace(0, 1, p0)\n",
    "    #pts = np.kron((1-t) ** 3, pt1) + np.kron(3*(1-t)**2 * t, pt2) + np.kron(3 * (1-t) * t**2, pt3) + np.kron(t**3, pt4)\n",
    "    pts = np.kron((1-t)**2, pt1) + np.kron(2*t*(1-t), pt2) + np.kron(t**2, pt3)\n",
    "    x1 = np.arange(1, p0+1)\n",
    "    y1 = np.round(pts[1, :]).astype(np.int64)\n",
    "    y1 = y1 - min(y1) + 1\n",
    "    #plot(x1,y1)\n",
    "    pp = np.max(y1)\n",
    "    PSF = np.zeros((p0, len(x1)))\n",
    "\n",
    "    print(len(x1), PSF.shape)\n",
    "\n",
    "    for ind_x in range(len(x1)):\n",
    "        yy = max(len(x1) - y1[ind_x], 1)\n",
    "        PSF[yy, ind_x] = np.random.rand()\n",
    "\n",
    "    PSF = PSF/(sum(PSF.ravel()) + eps*p0*p0)\n",
    "    return PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf = curved_psf()\n",
    "lifting_blurred = conv2(liftingbody, psf, 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(psf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = restoration.richardson_lucy(lifting_blurred, psf)\n",
    "plt.imshow(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore Image using Richardson-Lucy algorithm my:\n",
    "iterations = 3\n",
    "deconv = richardson_lucy_matlab(lifting_blurred, psf, iterations=iterations, eps=1e-5)\n",
    "deconv_py = restoration.richardson_lucy(lifting_blurred, psf, iterations=iterations)\n",
    "show_results(lifting_blurred, deconv_py, deconv['image'], titles=['Blurred data', 'Restoration using\\nRichardson-Lucy python', 'Restoration using\\nRichardson-Lucy my'])\n",
    "plot_corr(iterations+1, [deconv['correlationX'], \n",
    "                         deconv['correlationY']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейный оператор смаза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.draw import line_aa\n",
    "from math import sin, cos, pi\n",
    "def motion_blur_psf(length, angle):\n",
    "    cc, rr, val = line_aa(0, 0, int(length*cos(angle)), int(length*sin(angle)))\n",
    "    psf = np.zeros((max(rr)+1, max(cc)+1))\n",
    "    psf[rr, cc] = val\n",
    "    #psf[0, 0] = psf[0, 0]/2\n",
    "    #psf[-1, -1] = psf[-1, -1]/2\n",
    "    return psf/np.sum(psf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, pi\n",
    "\"\"\"Incorrectly works with angles k*pi/2, where k is integer.\"\"\"\n",
    "def motion_blur_psf_my(length=10, angle=pi/4, n_points=1000, **kwargs):\n",
    "    x_start, y_start = 0, 0\n",
    "    if 'x' in kwargs and 'y' in kwargs:\n",
    "        x_end, y_end = kwargs['x'], kwargs['y']\n",
    "    else:\n",
    "        x_end, y_end = length*cos(angle), length*sin(angle)\n",
    "    if x_end < 0:\n",
    "        x_start -= x_end\n",
    "        x_end = 0\n",
    "    if y_end < 0:\n",
    "        y_start -= y_end\n",
    "        y_end = 0\n",
    "    psf = np.zeros((int(max(y_start, y_end))+2, int(max(x_start, x_end))+2))\n",
    "    \n",
    "    triangle_fun = lambda x: np.maximum(0, (1 - np.abs(x)))\n",
    "    triangle_fun_prod = lambda x, y: np.multiply(triangle_fun(x), triangle_fun(y))\n",
    "    \n",
    "    X = np.linspace(x_start, x_end, n_points)\n",
    "    Y = np.linspace(y_start, y_end, n_points)\n",
    "    x1 = np.floor(X).astype(np.int)\n",
    "    x2 = x1+1\n",
    "    y1 = np.floor(Y).astype(np.int)\n",
    "    y2 = y1+1\n",
    "    print(x_start, y_start, x_end,y_end)\n",
    "    psf[y1, x1] += triangle_fun_prod(X - x1, Y - y1)\n",
    "    psf[y2, x1] += triangle_fun_prod(X - x1, Y - y2)\n",
    "    psf[y1, x2] += triangle_fun_prod(X - x2, Y - y1)\n",
    "    psf[y2, x2] += triangle_fun_prod(X - x2, Y - y2)\n",
    "    return psf/np.sum(psf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(motion_blur_psf_my(x=3,y=-4.5),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 30\n",
    "psf = motion_blur_psf_my(shift, pi/3)\n",
    "lifting_blurred = conv2(liftingbody, psf, 'same')\n",
    "iterations = 40\n",
    "deconv = richardson_lucy_matlab(lifting_blurred, psf, iterations=iterations, eps=1e-5, clip=False, dampar=0.004)\n",
    "show_results(liftingbody, lifting_blurred, deconv['image'])\n",
    "plot_corr(iterations+1, [deconv['correlationX'], \n",
    "                         deconv['correlationY']])\n",
    "correlation_X = pearsonr(liftingbody.ravel('C')[:-1], liftingbody.ravel('C')[1:])\n",
    "correlation_Y = pearsonr(liftingbody.ravel('F')[:-1], liftingbody.ravel('F')[1:])\n",
    "print(correlation_X, correlation_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Неверная psf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_wrong = motion_blur_psf(shift, pi/4)\n",
    "#iterations = 20\n",
    "deconv_wrong = richardson_lucy_matlab(lifting_blurred, psf_wrong, iterations=iterations, eps=1e-5)\n",
    "show_results(liftingbody, lifting_blurred, deconv_wrong['image'])\n",
    "plot_corr(iterations+1, [deconv['correlationX'], \n",
    "                         deconv['correlationY'],\n",
    "                         deconv_wrong['correlationX'],\n",
    "                         deconv_wrong['correlationY']], \n",
    "          legend=['row correlation', 'column correlation', 'row correlateion(wrong psf)', 'column correlation(wrong psf)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование параметра dampar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_noise(image):\n",
    "    N, M = image.shape\n",
    "    F = np.fft.fftn(image)\n",
    "    part = .02\n",
    "    area = F[int(N/2-N*part):int(N/2+N*part), int(M/2-M*part):int(M/2+M*part)]\n",
    "    np.std\n",
    "    np.var\n",
    "    msv = np.sqrt(np.mean(np.abs(area) ** 2) / (N*M))\n",
    "    I_res = np.fft.ifftn(F-msv)\n",
    "    NSR = msv**2 / np.var(I_res)\n",
    "    return (msv, NSR)\n",
    "s_n, S_find = find_noise(liftingbody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf = motion_blur_psf(shift, pi/4)\n",
    "lifting_blurred = conv2(liftingbody, psf, 'same')\n",
    "iterations = 30\n",
    "deconv = richardson_lucy_matlab(lifting_blurred, psf, iterations=iterations, eps=1e-5, clip=False, dampar=s_n)\n",
    "show_results(liftingbody, lifting_blurred, deconv['image'])\n",
    "plot_corr(iterations+1, [deconv['correlationX'], \n",
    "                         deconv['correlationY']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dampar и неверная psf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_wrong = motion_blur_psf_my(shift, pi/3)\n",
    "#iterations = 40\n",
    "deconv_wrong = richardson_lucy_matlab(lifting_blurred, psf_wrong, iterations=iterations, eps=1e-5, dampar=s_n)\n",
    "show_results(liftingbody, lifting_blurred, deconv_wrong['image'])\n",
    "plot_corr(iterations+1, [deconv['correlationX'], \n",
    "                         deconv['correlationY'],\n",
    "                         deconv_wrong['correlationX'],\n",
    "                         deconv_wrong['correlationY']], \n",
    "          legend=['row correlation', 'column correlation', 'row correlateion(wrong psf)', 'column correlation(wrong psf)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "\n",
    "w, h = lifting_blurred.shape\n",
    "x = np.arange(w)\n",
    "y = np.arange(h)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, F, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "# Customize the z axis.\n",
    "#ax.set_zlim(0, 1.01)\n",
    "#ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "#ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "#fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кепстр\n",
    "$$K = F^{-1}\\{log(1+\\left|F\\{I\\}\\right|)\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "\n",
    "b_clip = 3\n",
    "N,M = lifting_blurred.shape\n",
    "# ( ifft2 (100* log (1+ abs ( fft2 ( I ) ) ) ) ) ;\n",
    "K = np.fft.ifftn(100*np.log(1+np.abs(np.fft.fftn(lifting_blurred))))#[b_clip:N//2,b_clip:M//2]\n",
    "K_shift = np.fft.fftshift(K)\n",
    "#K = gaussian(np.abs(K), 1)\n",
    "\n",
    "#mask = np.ones((N, M))\n",
    "#mask[1:3, 1:3] = 0\n",
    "#K *= mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "\n",
    "h, w = K.shape\n",
    "x = np.arange(w)\n",
    "y = np.arange(h)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "print(X.shape, Y.shape)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "# Plot the surface.\n",
    "H = 1\n",
    "surf = ax.plot_surface(X, Y, np.abs(K_shift), cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "# Customize the z axis.\n",
    "#ax.set_zlim(0, H + H/20)\n",
    "#ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "#ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "#fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = np.argmin(np.real(K_shift))\n",
    "n, m, = K_shift.shape\n",
    "x0 = [nn // n - n//2, nn % n - m//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(np.clip(np.real(K_shift),-1,1))#, vmin=noisy.min(), vmax=noisy.max())\n",
    "plt.plot(n//2 + x0[0], m//2 + x0[1], 'ro')\n",
    "plt.title('Кепстр изображения с выделенным минмиумом')\n",
    "plt.savefig('kepstr.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уточнение искажающего оператора\n",
    "$$\\varepsilon = ||\\tilde{I}\\oplus\\tilde{h}-I_0|| \\to \\min_{(x,y)}$$\n",
    "Пусть $$\\tilde{I}\\oplus(\\tilde{h}+\\tilde{dh})=I_0$$\n",
    "Тогда $$\\tilde{I}\\oplus\\tilde{dh}=I_0-\\tilde{I}\\oplus\\tilde{h}$$\n",
    "Получим задачу аналогичную исходной($\\tilde{I}\\oplus h +\\eta = I_0$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "img_diff = liftingbody - convolve2d(deconv['image'], psf, mode='same') # Утечка\n",
    "deconv_psf = richardson_lucy_matlab(img_diff, deconv['image'], iterations=iterations, eps=1e-5, dampar=s_n, useFFT=True)\n",
    "psf_new = deconv_psf['image']\n",
    "deconv_upd = richardson_lucy_matlab(lifting_blurred, psf_new, iterations=iterations, eps=1e-5, dampar=s_n, useFFT=True)\n",
    "show_results(lifting_blurred, deconv['image'], deconv_upd['image'],\n",
    "             titles=['blurred', 'restored', 'restored with\\nnew psf'])\n",
    "plot_corr(iterations+1, [deconv['correlationX'], \n",
    "                         deconv['correlationY'],\n",
    "                         deconv_upd['correlationX'],\n",
    "                         deconv_upd['correlationY']], \n",
    "          legend=['row correlation', 'column correlation', 'row correlateion(new psf)', 'column correlation(new psf)'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такой подход не сработал :( Будем использовать метод Ньютона\n",
    "## Уточнение искажающего оператора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "def funcToMinimize(xy, I_blurred, *args, **kwargs):\n",
    "    psf = motion_blur_psf_my(x=xy[0], y=xy[1])\n",
    "    restored = richardson_lucy_matlab(I_blurred, psf, *args, **kwargs)\n",
    "    I_restored = restored['image']\n",
    "    df = convolve2d(I_restored, psf, 'same') - I_blurred\n",
    "    return np.mean(np.square(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial(funcToMinimize, I_blurred=lifting_blurred, iterations=iterations, eps=1e-5, dampar=s_n, useFFT=True)([10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos(pi/4)*30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Минимизация методом Нелдера-Мида (симплекс-метод)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# 0 0 19.92055100537836 23.428020572755493\n",
    "# Optimization terminated successfully.\n",
    "#          Current function value: 0.000656\n",
    "#          Iterations: 27\n",
    "#          Function evaluations: 66\n",
    "\n",
    "# res = minimize(partial(funcToMinimize, I_blurred=lifting_blurred, iterations=iterations, eps=1e-5, dampar=s_n, useFFT=True),\n",
    "#                x0=x0, method='Nelder-Mead',\n",
    "#                options={'xtol': 1e-3, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод Пауэлла (метод спуска по векторам с использованием квадратичной аппроксимации)\n",
    "# Время работы большое(не дождался)\n",
    "\n",
    "# res_powell = minimize(partial(funcToMinimize, I_blurred=lifting_blurred, iterations=iterations, eps=1e-5, dampar=s_n, useFFT=True),\n",
    "#                x0=x0, method='Powell',\n",
    "#                options={'xtol': 1e-3, 'disp': True})\n",
    "# print(res_powell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Метод сопряжённых градиентов](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D1%81%D0%BE%D0%BF%D1%80%D1%8F%D0%B6%D1%91%D0%BD%D0%BD%D1%8B%D1%85_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82%D0%BE%D0%B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод сопряжённых градиентов\n",
    "# Очень медленно движется в верном направлении\n",
    "# 0 0 21.94429490476539 21.999610267537243\n",
    "# 0 0 21.94429490476539 21.999610267537243\n",
    "# 0 0 21.94429491966655 21.999610267537243\n",
    "\n",
    "# res_cg = minimize(partial(funcToMinimize, I_blurred=lifting_blurred, iterations=iterations, eps=1e-5, dampar=s_n, useFFT=True),\n",
    "#                x0=x0, method='CG')\n",
    "# print(res_cg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BFGS](https://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%91%D1%80%D0%BE%D0%B9%D0%B4%D0%B5%D0%BD%D0%B0_%E2%80%94_%D0%A4%D0%BB%D0%B5%D1%82%D1%87%D0%B5%D1%80%D0%B0_%E2%80%94_%D0%93%D0%BE%D0%BB%D1%8C%D0%B4%D1%84%D0%B0%D1%80%D0%B1%D0%B0_%E2%80%94_%D0%A8%D0%B0%D0%BD%D0%BD%D0%BE)\n",
    "квазиньютоновский метод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Алгоритм Бройдена — Флетчера — Гольдфарба — Шанно (BFGS)\n",
    "# fun: 0.000661486767220792\n",
    "#  hess_inv: array([[3.50190492e-09, 4.84852786e-09],\n",
    "#        [4.84852786e-09, 6.73400920e-09]])\n",
    "#       jac: array([ 1.071819  , -0.53368984])\n",
    "#   message: 'Desired error not necessarily achieved due to precision loss.'\n",
    "#      nfev: 384\n",
    "#       nit: 4\n",
    "#      njev: 93\n",
    "#    status: 2\n",
    "#   success: False\n",
    "#         x: array([21.9432086 , 21.99968588])\n",
    "\n",
    "# res_bfgs = minimize(partial(funcToMinimize, I_blurred=lifting_blurred, iterations=iterations, eps=1e-5, dampar=s_n, useFFT=True),\n",
    "#                x0=x0, method='BFGS')\n",
    "# print(res_bfgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! Jacobian is requiered\n",
    "# res_newton_cg = minimize(partial(funcToMinimize, I_blurred=lifting_blurred, iterations=iterations, eps=1e-5, dampar=s_n, useFFT=True),\n",
    "#                x0=x0, method='Newton-CG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L-BFGS-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# быстро\n",
    "# 0 0 22.00000309066789 22.000001525058693\n",
    "# 0 0 22.00000309066789 22.000001515058692\n",
    "# 0 0 22.00000310066789 22.000001515058692\n",
    "# 0 0 22.00000309066789 22.000001525058693\n",
    "#       fun: 0.0009062932190944391\n",
    "#  hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
    "#       jac: array([ 1.54585227, 31.06279667])\n",
    "#   message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
    "#      nfev: 90\n",
    "#       nit: 2\n",
    "#    status: 0\n",
    "#   success: True\n",
    "#         x: array([22.00000309, 22.00000152])\n",
    "\n",
    "# res_l_bfgs_b = minimize(partial(funcToMinimize, I_blurred=lifting_blurred, iterations=iterations, eps=1e-5, dampar=s_n, useFFT=True),\n",
    "#                x0=x0, method='L-BFGS-B')\n",
    "# print(res_l_bfgs_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TNC - truncated Newton (for optimizing non-linear functions with large numbers of independent variables.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "res_tnc = minimize(partial(funcToMinimize, I_blurred=lifting_blurred, iterations=iterations, eps=1e-5, dampar=s_n, useFFT=True),\n",
    "               x0=x0, method='TNC')\n",
    "print(res_tnc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method Nelder-Mead uses the Simplex algorithm [1], [2]. This algorithm is robust in many applications. However, if numerical computation of derivative can be trusted, other algorithms using the first and/or second derivatives information might be preferred for their better performance in general.\n",
    "\n",
    "Method Powell is a modification of Powell’s method [3], [4] which is a conjugate direction method. It performs sequential one-dimensional minimizations along each vector of the directions set (direc field in options and info), which is updated at each iteration of the main minimization loop. The function need not be differentiable, and no derivatives are taken.\n",
    "\n",
    "Method CG uses a nonlinear conjugate gradient algorithm by Polak and Ribiere, a variant of the Fletcher-Reeves method described in [5] pp. 120-122. Only the first derivatives are used.\n",
    "\n",
    "Method BFGS uses the quasi-Newton method of Broyden, Fletcher, Goldfarb, and Shanno (BFGS) [5] pp. 136. It uses the first derivatives only. BFGS has proven good performance even for non-smooth optimizations. This method also returns an approximation of the Hessian inverse, stored as hess_inv in the OptimizeResult object.\n",
    "\n",
    "Method Newton-CG uses a Newton-CG algorithm [5] pp. 168 (also known as the truncated Newton method). It uses a CG method to the compute the search direction. See also TNC method for a box-constrained minimization with a similar algorithm. Suitable for large-scale problems.\n",
    "\n",
    "Method dogleg uses the dog-leg trust-region algorithm [5] for unconstrained minimization. This algorithm requires the gradient and Hessian; furthermore the Hessian is required to be positive definite.\n",
    "\n",
    "Method trust-ncg uses the Newton conjugate gradient trust-region algorithm [5] for unconstrained minimization. This algorithm requires the gradient and either the Hessian or a function that computes the product of the Hessian with a given vector. Suitable for large-scale problems.\n",
    "\n",
    "Method trust-krylov uses the Newton GLTR trust-region algorithm [14], [15] for unconstrained minimization. This algorithm requires the gradient and either the Hessian or a function that computes the product of the Hessian with a given vector. Suitable for large-scale problems. On indefinite problems it requires usually less iterations than the trust-ncg method and is recommended for medium and large-scale problems.\n",
    "\n",
    "Method trust-exact is a trust-region method for unconstrained minimization in which quadratic subproblems are solved almost exactly [13]. This algorithm requires the gradient and the Hessian (which is not required to be positive definite). It is, in many situations, the Newton method to converge in fewer iteraction and the most recommended for small and medium-size problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv_orig = richardson_lucy_matlab(lifting_blurred, psf, iterations=iterations, dampar=s_n, useFFT=False)\n",
    "psnr_orig = compare_psnr(liftingbody, deconv_orig['image'])\n",
    "\n",
    "psf_init = motion_blur_psf_my(x=x0[0], y=x0[1])\n",
    "deconv_init = richardson_lucy_matlab(lifting_blurred, psf_init, iterations=iterations, dampar=s_n, useFFT=False)\n",
    "psnr_init = compare_psnr(liftingbody, deconv_init['image'])\n",
    "\n",
    "x_found, y_found = res_tnc['x']\n",
    "psf_found = motion_blur_psf_my(x=x_found, y=y_found)\n",
    "deconv_found = richardson_lucy_matlab(lifting_blurred, psf_found, iterations=iterations, dampar=s_n, useFFT=False)\n",
    "psnr_found = compare_psnr(liftingbody, deconv_found['image'])\n",
    "\n",
    "show_results(deconv_orig['image'], deconv_init['image'], deconv_found['image'],\n",
    "             titles=['Restored with true psf\\nPSNR={0}'.format(psnr_orig), \n",
    "                     'With initial approxiamtion\\nPSNR={0}'.format(psnr_init),\n",
    "                     'Minimized error\\nPSNR={0}'.format(psnr_found)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка криволинейного искажающего оператора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.draw import line_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 20\n",
    "r, c = bezier_curve(0, 0, sz//10, sz-1 - sz//10, sz-1, sz-1, weight=1)\n",
    "#r, c, val = line_aa(0, 0, 15, 19)\n",
    "#r, c = bezier_curve(0, 0, sz//2, sz//2, sz-1, sz-1, weight=1)\n",
    "psf_bezier = np.zeros((sz, sz))\n",
    "psf_bezier[r, c] = 1\n",
    "psf_bezier /= psf_bezier.sum()\n",
    "\n",
    "iterations = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_bezier.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifting_bezier_blurred = convolve2d(liftingbody, psf_bezier, 'same')\n",
    "#lifting_restored = restoration.richardson_lucy(lifting_bezier_blurred, psf_bezier, iterations=iterations)\n",
    "deconv_bezier = richardson_lucy_matlab(lifting_bezier_blurred, psf_bezier, iterations=iterations, clip=True, useFFT=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('iterations = {0}'.format(iterations))\n",
    "#show_results(lifting_bezier_blurred, lifting_restored, deconv_bezier['image'],\n",
    "#            titles = ['Blurred data', 'Restored with python LR', 'Restored with my LR'])\n",
    "show_results(liftingbody, lifting_bezier_blurred, deconv_bezier['image'])\n",
    "plot_corr(iterations+1, [deconv_bezier['correlationX'], \n",
    "                         deconv_bezier['correlationY']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv_bezier['image']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample log\n",
    "```\n",
    "0 0 21.0 21.0\n",
    "0 0 22.05 21.0\n",
    "0 0 21.0 22.05\n",
    "0 0 19.95 22.049999999999997\n",
    "0 0 21.525 21.2625\n",
    "0 0 21.525 20.212500000000002\n",
    "0 0 21.13125 21.590625000000003\n",
    "0 0 21.65625 21.853125000000006\n",
    "0 0 21.4921875 21.639843750000004\n",
    "0 0 21.885937499999997 21.311718749999997\n",
    "0 0 21.697265624999996 21.3814453125\n",
    "0 0 21.664453125 21.758789062500004\n",
    "0 0 21.55986328125 21.386572265625\n",
    "0 0 21.5947265625 21.51064453125\n",
    "0 0 21.50859375 21.451171875\n",
    "0 0 21.5783203125 21.699316406250006\n",
    "0 0 21.475781249999997 21.82851562500001\n",
    "0 0 21.564990234375 21.5901123046875\n",
    "0 0 21.53525390625 21.669580078125005\n",
    "0 0 21.54345703125 21.575244140625003\n",
    "0 0 21.483984375 21.734179687500003\n",
    "0 0 21.498852539062497 21.694445800781253\n",
    "0 0 21.4557861328125 21.664709472656252\n",
    "0 0 21.515386962890624 21.668362426757817\n",
    "0 0 21.52205200195312 21.722964477539065\n",
    "0 0 21.49965362548828 21.66062393188477\n",
    "0 0 21.50711975097656 21.681404113769535\n",
    "0 0 21.503787231445312 21.65410308837891\n",
    "0 0 21.51205444335937 21.641061401367192\n",
    "0 0 21.50835342407226 21.67131843566895\n",
    "0 0 21.509587097167966 21.661232757568364\n",
    "0 0 21.511253356933594 21.674883270263678\n",
    "0 0 21.513720703124996 21.654711914062503\n",
    "0 0 21.519520568847653 21.661841583251956\n",
    "0 0 21.524487304687497 21.662145996093756\n",
    "0 0 21.526153564453125 21.67579650878907\n",
    "0 0 21.51682891845703 21.659983062744146\n",
    "0 0 21.51993713378906 21.665254211425786\n",
    "0 0 21.519104003906246 21.65842895507813\n",
    "0 0 21.523654174804687 21.6553207397461\n",
    "0 0 21.52086639404297 21.662770843505864\n",
    "0 0 21.52272491455078 21.65780410766602\n",
    "0 0 21.51734161376953 21.65408706665039\n",
    "0 0 21.522700881958006 21.660131263732914\n",
    "0 0 21.520914459228514 21.658116531372073\n",
    "0 0 21.521795654296874 21.660287475585942\n",
    "0 0 21.518222808837884 21.65625801086426\n",
    "0 0 21.516412353515612 21.656570434570312\n",
    "0 0 21.51978893280029 21.657730007171633\n",
    "0 0 21.518663406372063 21.657343482971193\n",
    "0 0 21.52000923156738 21.6582727432251\n",
    "0 0 21.517758178710928 21.65749969482422\n",
    "0 0 21.518198776245107 21.658585166931154\n",
    "0 0 21.518547248840324 21.657653903961183\n",
    "0 0 21.519893074035643 21.65858316421509\n",
    "0 0 21.518291902542106 21.65777056217194\n",
    "Optimization terminated successfully.\n",
    "         Current function value: 0.000638\n",
    "         Iterations: 23\n",
    "         Function evaluations: 56\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "802px",
    "left": "0px",
    "right": "1641px",
    "top": "111px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
