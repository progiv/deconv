{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка линейного искажающего оператора в задаче восстановления изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import convolve2d as conv2\n",
    "\n",
    "from skimage import color, data, restoration, io, img_as_float\n",
    "from skimage.restoration import uft\n",
    "from scipy.signal import fftconvolve, convolve, convolve2d\n",
    "from scipy.stats.stats import pearsonr\n",
    "from numpy.fft import fftn, ifftn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interactive graphics\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "sz = 11\n",
    "astro = color.rgb2gray(data.astronaut())\n",
    "\n",
    "psf = np.ones((sz, sz)) / (sz*sz)\n",
    "astro_noisy = conv2(astro, psf, 'same')\n",
    "# Add Noise to Image\n",
    "#astro_noisy += (np.random.poisson(lam=25, size=astro.shape) - 10) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(original, noisy, result, titles=['Original Data', 'Blurred data', 'Restoration using\\nRichardson-Lucy']):\n",
    "    # Show results\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(12, 10))\n",
    "    plt.gray()\n",
    "\n",
    "    for a in (ax[0], ax[1], ax[2]):\n",
    "           a.axis('off')\n",
    "\n",
    "    ax[0].imshow(original)\n",
    "    ax[0].set_title(titles[0])\n",
    "\n",
    "    ax[1].imshow(noisy)\n",
    "    ax[1].set_title(titles[1])\n",
    "\n",
    "    ax[2].imshow(result, vmin=noisy.min(), vmax=noisy.max())\n",
    "    ax[2].set_title(titles[2])\n",
    "\n",
    "\n",
    "    fig.subplots_adjust(wspace=0.02, hspace=0.2,\n",
    "                        top=0.9, bottom=0.05, left=0, right=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_correlation(image):\n",
    "    return pearsonr(image[1:,:].ravel(), image[:-1,:].ravel())[0]\n",
    "    \n",
    "def col_correlation(image):\n",
    "    return pearsonr(image[:,1:].ravel(), image[:,:-1].ravel())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desubsample(image, times=1, axises=None):\n",
    "    if axises is None:\n",
    "        axises = [i for i, sz in enumerate(image.shape) if sz > 4]\n",
    "    for axis in axises:\n",
    "        image = image.repeat(times, axis)#, inplace=True)\n",
    "    return image\n",
    "\n",
    "def corelucy(Y, psf, dampar22, wI, readout, subsample, numNSdim, vec, num, eps=1e-9, useFFT=False):\n",
    "    \"\"\"\n",
    "    CORELUCY Accelerated Damped Lucy-Richarson Operator.\n",
    "    Calculates function that when used with the scaled projected array\n",
    "    produces the next iteration array that maximizes the likelihood that\n",
    "    the entire suite satisfies the Poisson statistics.\n",
    "    \"\"\"\n",
    "    if useFFT:\n",
    "        reBlurred = np.real(ifftn(fftn(Y) * psf)) #Here psf=H = fftn(psf)\n",
    "    else:\n",
    "        reBlurred = np.real(convolve2d(Y, psf, 'same'))\n",
    "\n",
    "    # 1. Resampling if needed\n",
    "    if subsample != 1: # Bin reBlurred back to the sizeI for non-singleton dims\n",
    "        #1.Reshape so that the-to-binned dimension separates into two\n",
    "        #dimensions, with one of them consisting of elements of a single bin.\n",
    "        reBlurred = np.reshape(reBlurred, vec);\n",
    "\n",
    "        #2. Bin (==calculate mean) along the first of the-to-binned dimension,\n",
    "        #that dimension consists of the bin elements. Reshape to get rid off\n",
    "        for k in num: # new appeared singleton.\n",
    "            vec.pop(k) #~ vec(k) = [];\n",
    "            reBlurred = reshape(mean(reBlurred,k),vec);\n",
    "\n",
    "    # 2. An Estimate for the next step\n",
    "    reBlurred += readout;\n",
    "    #reBlurred[reBlurred == 0] = eps;\n",
    "    AnEstim = wI / (reBlurred + eps);\n",
    "\n",
    "    # 3. Damping if needed\n",
    "    if dampar22 == 0: # No Damping\n",
    "        ImRatio = desubsample(AnEstim, subsample, numNSdim);\n",
    "    else: # Damping of the image relative to dampar22 = (N*sigma)^2\n",
    "        gm = 10;\n",
    "        g = (wI * np.log(AnEstim)+ reBlurred - wI) / dampar22;\n",
    "        g = np.minimum(g,1);\n",
    "        G = (g**(gm-1))*(gm-(gm-1)*g);\n",
    "        ImRatio = 1 + desubsample(G,subsample, numNSdim) * (desubsample(AnEstim, subsample, numNSdim) - 1);\n",
    "    if useFFT:\n",
    "        return fftn(ImRatio);\n",
    "    else:\n",
    "        return ImRatio\n",
    "\n",
    "def richardson_lucy_matlab(image, psf, iterations=50, dampar=0, weight=None, readout=0, \n",
    "                           subsample=1, eps=1e-16, clip=True, useFFT=False):\n",
    "    \"\"\" Richardson-Lucy deconvolution.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : ndarray\n",
    "       Input degraded image (can be N dimensional).\n",
    "    psf : ndarray\n",
    "       The point spread function.\n",
    "    iterations : int\n",
    "       Number of iterations. This parameter plays the role of\n",
    "       regularisation.\n",
    "    \"\"\"\n",
    "    #if 'eps' not in globals():\n",
    "    #    eps = 1e-9\n",
    "    # to continue restoration\n",
    "    sizeI = image.shape\n",
    "    sizePSF = psf.shape\n",
    "    numNSdim = [i for i, sz in enumerate(sizePSF) if sz > 4] # do not desubsample rgb axis\n",
    "\n",
    "    assert(not np.all(psf == 0))\n",
    "\n",
    "    if isinstance(image, list) and len(image) == 4:\n",
    "        image, prev_image, prev_prev_image, internal = image\n",
    "    else:\n",
    "        prev_image = np.ones(image.shape)*.5#image\n",
    "        prev_prev_image = 0\n",
    "        internal = np.zeros((image.size*subsample**len(numNSdim),2))\n",
    "    internal[:,1] = 0\n",
    "\n",
    "    if weight is None:\n",
    "        weight = np.ones(image.shape)\n",
    "\n",
    "    # 1. Prepare OTF\n",
    "    #~ H = psf2otf(psf, sizeI);\n",
    "    if psf.shape != image.shape:\n",
    "        H = uft.ir2tf(psf, image.shape, is_real=False)\n",
    "    else:\n",
    "        H = psf\n",
    "\n",
    "    wI = np.maximum(weight * (readout + image), 0)\n",
    "    prev_image = desubsample(prev_image, subsample, numNSdim)\n",
    "    if useFFT:\n",
    "        scale = np.real(ifftn(np.conj(H)*fftn(desubsample(weight)))) + np.sqrt(eps)\n",
    "    else:\n",
    "        scale = np.real(convolve2d(desubsample(weight), psf, 'same')) + np.sqrt(eps)\n",
    "    del weight\n",
    "\n",
    "    dampar22 = np.square(dampar)/2\n",
    "\n",
    "    '''\n",
    "    prepare vector of dimensions to facilitate the reshaping\n",
    "    % when the matrix is binned within the iterations.\n",
    "    '''\n",
    "    vec = []\n",
    "    num = []\n",
    "    if subsample != 1:\n",
    "        for dim, sz in enumerate(sizeI):\n",
    "            if sz != 1:\n",
    "                vec.extend((subsample, sz))\n",
    "                num.append(dim)\n",
    "            else:\n",
    "                vec.append(sz)\n",
    "    num.reverse()\n",
    "\n",
    "    # 3 L_R Iterations\n",
    "    lambd = 2 * np.any(internal != 0)\n",
    "    correlation_X = [col_correlation(image)]\n",
    "    correlation_Y = [row_correlation(image)]\n",
    "    for k in range(lambd, lambd + iterations):\n",
    "\n",
    "        # 3.a Make an image predictions for the next iteration\n",
    "        if k > 2:\n",
    "            lambd = (internal[:,0].T.dot(internal[:,1])) / (internal[:,1].T.dot(internal[:,1]) +eps) # (scalar division)\n",
    "            lambd = max(min(lambd, 1), 0) # stability enforcement saturation\n",
    "        Y = np.maximum(prev_image + lambd*(prev_image - prev_prev_image), 0) # plus positivity constraint\n",
    "\n",
    "        # 3.b Make core for the LR estimation\n",
    "        if useFFT:\n",
    "            cc = corelucy(Y, H, dampar22, wI, readout, subsample, numNSdim, vec, num, eps, useFFT)\n",
    "        else:\n",
    "            cc = corelucy(Y, psf, dampar22, wI, readout, subsample, numNSdim, vec, num, eps, useFFT)\n",
    "\n",
    "        # 3.c Determine next iteration image and apply poitivity constraint\n",
    "        prev_prev_image = prev_image\n",
    "        if useFFT:\n",
    "            prev_image = np.maximum(Y * np.real(ifftn(cc * H)) / scale, 0)\n",
    "        else:\n",
    "            prev_image = np.maximum(Y * np.real(convolve2d(cc, psf, 'same')) / scale, 0)\n",
    "        if clip:\n",
    "            prev_image[prev_image > 1] = 1\n",
    "            prev_image[prev_image < -1] = eps\n",
    "        correlation_X.append(col_correlation(prev_image))\n",
    "        correlation_Y.append(row_correlation(prev_image))\n",
    "        del cc\n",
    "        internal[:,1] = internal[:,0]\n",
    "        internal[:,0] = (prev_image-Y).ravel()\n",
    "    del wI, H, scale, Y\n",
    "    return {'image': prev_image, \n",
    "            'correlationX': np.array(correlation_X)/(image.size-1), \n",
    "            'correlationY': np.array(correlation_Y)/(image.size-1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def plot_corr(n, ydata, legend=['row correlation', 'column correlation'], title='Normalized correlation'):\n",
    "    plt.plot(*list(chain(*[(range(n), y) for y in ydata])))\n",
    "    plt.grid()\n",
    "    plt.title(title)\n",
    "    plt.xlabel('n iterations')\n",
    "    plt.legend(legend)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore Image using Richardson-Lucy algorithm:\n",
    "iterations = 20\n",
    "deconv = richardson_lucy_matlab(astro_noisy, psf, iterations=iterations, eps=1e-5)\n",
    "show_results(astro, astro_noisy, deconv['image'])\n",
    "plot_corr(iterations+1, [deconv['correlationX'], \n",
    "                         deconv['correlationY']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liftingbody = img_as_float(io.imread('liftingbody.png'))\n",
    "lifting_blurred = conv2(liftingbody, psf, 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore Image using Richardson-Lucy algorithm my:\n",
    "iterations = 20\n",
    "deconv = richardson_lucy_matlab(lifting_blurred, psf, iterations=iterations, eps=1e-5, useFFT=True)\n",
    "show_results(liftingbody, lifting_blurred, deconv['image'])\n",
    "plot_corr(iterations+1, [deconv['correlationX'], \n",
    "                         deconv['correlationY']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// matlab original for gen psf (curved line shift)\n",
    "```python\n",
    "def gen_psf():\n",
    "    p0 = np.random.randint(6, 25)\n",
    "    p1 = np.random.randint(6, 21)\n",
    "\n",
    "    x = np.random.randint(0, p0, (1,4))#sort(randi([0 p0], 1, 4));\n",
    "    y = np.random.randint(0, p1, (1,4))\n",
    "\n",
    "    pt1 = [x[0]; y[0]]\n",
    "    pt2 = [x[1]; y[1]]\n",
    "    pt3 = [x[2]; y[2]]\n",
    "    pt4 = [x[3]; y[3]]\n",
    "\n",
    "    t = list(range(0, p0+1))\n",
    "    pts = kron((1-t).^3,pt1) + kron(3*(1-t).^2.*t,pt2) + kron(3*(1-t).*t.^2,pt3) + kron(t.^3,pt4);\n",
    "    x1 = 1:p0;\n",
    "    y1 = round(pts(2, :));\n",
    "    y1 = y1 - min(y1) + 1;\n",
    "    %plot(x1,y1);\n",
    "    pp = max(y1);\n",
    "    PSF = zeros(p0, pp);\n",
    "\n",
    "    for ind_x = 1:length(x1)\n",
    "        yy = max(length(x1) - y1(ind_x), 1);\n",
    "        PSF(yy, ind_x) = rand();\n",
    "    end\n",
    "\n",
    "    PSF = PSF./(sum(PSF(:)) + eps*p0*p0);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Криволинейный оператор смаза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def curved_psf():\n",
    "    eps = 1e-16\n",
    "    p0 = np.random.randint(6, 25)\n",
    "    p1 = np.random.randint(6, 21)\n",
    "\n",
    "    x = np.random.randint(0, p0, 4)#sort(randi([0 p0], 1, 4));\n",
    "    y = np.random.randint(0, p1, 4)\n",
    "\n",
    "    pt1 = [[x[0]], [y[0]]]\n",
    "    pt2 = [[x[1]], [y[1]]]\n",
    "    pt3 = [[x[2]], [y[2]]]\n",
    "    pt4 = [[x[3]], [y[3]]]\n",
    "\n",
    "    t = np.linspace(0, 1, p0)\n",
    "    pts = np.kron((1-t) ** 3, pt1) + np.kron(3*(1-t)**2 * t, pt2) + np.kron(3 * (1-t) * t**2, pt3) + np.kron(t**3, pt4)\n",
    "    x1 = np.arange(1, p0+1)\n",
    "    y1 = np.round(pts[1, :]).astype(np.int64)\n",
    "    y1 = y1 - min(y1) + 1\n",
    "    #plot(x1,y1)\n",
    "    pp = np.max(y1)\n",
    "    PSF = np.zeros((p0, len(x1)))\n",
    "\n",
    "    print(len(x1), PSF.shape)\n",
    "\n",
    "    for ind_x in range(len(x1)):\n",
    "        yy = max(len(x1) - y1[ind_x], 1)\n",
    "        PSF[yy, ind_x] = np.random.rand()\n",
    "\n",
    "    PSF = PSF/(sum(PSF.ravel()) + eps*p0*p0)\n",
    "    return PSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf = curved_psf()\n",
    "lifting_blurred = conv2(liftingbody, psf, 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore Image using Richardson-Lucy algorithm my:\n",
    "iterations = 3\n",
    "deconv = richardson_lucy_matlab(lifting_blurred, psf, iterations=iterations, eps=1e-5)\n",
    "show_results(liftingbody, lifting_blurred, deconv['image'])\n",
    "plot_corr(iterations+1, [deconv['correlationX'], \n",
    "                         deconv['correlationY']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейный оператор смаза"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.draw import line_aa\n",
    "from math import sin, cos, pi\n",
    "def motion_blur_psf(length, angle):\n",
    "    rr, cc, val = line_aa(0, 0, int(length*cos(angle)), int(length*sin(angle)))\n",
    "    psf = np.zeros((max(rr)+1, max(cc)+1))\n",
    "    psf[rr, cc] = val\n",
    "    #psf[0, 0] = psf[0, 0]/2\n",
    "    #psf[-1, -1] = psf[-1, -1]/2\n",
    "    return psf/np.sum(psf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift = 11\n",
    "psf = motion_blur_psf(shift, pi/3)\n",
    "lifting_blurred = conv2(liftingbody, psf, 'same')\n",
    "iterations = 20\n",
    "deconv = richardson_lucy_matlab(lifting_blurred, psf, iterations=iterations, eps=1e-5, clip=False)\n",
    "show_results(liftingbody, lifting_blurred, deconv['image'])\n",
    "plot_corr(iterations+1, [deconv['correlationX'], \n",
    "                         deconv['correlationY']])\n",
    "correlation_X = pearsonr(liftingbody.ravel('C')[:-1], liftingbody.ravel('C')[1:])\n",
    "correlation_Y = pearsonr(liftingbody.ravel('F')[:-1], liftingbody.ravel('F')[1:])\n",
    "print(correlation_X, correlation_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Неверная psf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_wrong = motion_blur_psf(shift, pi/2)\n",
    "iterations = 20\n",
    "deconv_wrong = richardson_lucy_matlab(lifting_blurred, psf_wrong, iterations=iterations, eps=1e-5)\n",
    "show_results(liftingbody, lifting_blurred, deconv_wrong['image'])\n",
    "plot_corr(iterations+1, [deconv['correlationX'], \n",
    "                         deconv['correlationY'],\n",
    "                         deconv_wrong['correlationX'],\n",
    "                         deconv_wrong['correlationY']], \n",
    "          legend=['row correlation', 'column correlation', 'row correlateion(wrong psf)', 'column correlation(wrong psf)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование параметра dampar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_noise(image):\n",
    "    N, M = image.shape\n",
    "    F = np.fft.fftn(image)\n",
    "    part = .02\n",
    "    area = F[int(N/2-N*part):int(N/2+N*part), int(M/2-M*part):int(M/2+M*part)]\n",
    "    np.std\n",
    "    np.var\n",
    "    msv = np.sqrt(np.mean(np.abs(area) ** 2) / (N*M))\n",
    "    I_res = np.fft.ifftn(F-msv)\n",
    "    NSR = msv**2 / np.var(I_res)\n",
    "    return (msv, NSR)\n",
    "s_n, S_find = find_noise(liftingbody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf = motion_blur_psf(shift, pi/3)\n",
    "lifting_blurred = conv2(liftingbody, psf, 'same')\n",
    "iterations = 40\n",
    "deconv = richardson_lucy_matlab(lifting_blurred, psf, iterations=iterations, eps=1e-5, clip=False, dampar=s_n)\n",
    "show_results(liftingbody, lifting_blurred, deconv['image'])\n",
    "plot_corr(iterations+1, [deconv['correlationX'], \n",
    "                         deconv['correlationY']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dampar и неверная psf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psf_wrong = motion_blur_psf(shift, pi/2)\n",
    "#iterations = 40\n",
    "deconv_wrong = richardson_lucy_matlab(lifting_blurred, psf_wrong, iterations=iterations, eps=1e-5, dampar=s_n)\n",
    "show_results(liftingbody, lifting_blurred, deconv_wrong['image'])\n",
    "plot_corr(iterations+1, [deconv['correlationX'], \n",
    "                         deconv['correlationY'],\n",
    "                         deconv_wrong['correlationX'],\n",
    "                         deconv_wrong['correlationY']], \n",
    "          legend=['row correlation', 'column correlation', 'row correlateion(wrong psf)', 'column correlation(wrong psf)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "\n",
    "w, h = lifting_blurred.shape\n",
    "x = np.arange(w)\n",
    "y = np.arange(h)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "# Plot the surface.\n",
    "surf = ax.plot_surface(X, Y, F, cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "# Customize the z axis.\n",
    "#ax.set_zlim(0, 1.01)\n",
    "#ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "#ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "#fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кепстр\n",
    "$$K = F^{-1}\\{log(1+\\left|F\\{I\\}\\right|)\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "\n",
    "b_clip = 50\n",
    "K = np.fft.ifftn(100*np.log(1+np.abs(np.fft.fftn(lifting_blurred))))[b_clip:-b_clip,b_clip:-b_clip]\n",
    "K = gaussian(np.abs(K))\n",
    "#N,M = K.shape\n",
    "#mask = np.ones((N, M))\n",
    "#mask[1:3, 1:3] = 0\n",
    "#K *= mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "\n",
    "w, h = K.shape\n",
    "x = np.arange(w)\n",
    "y = np.arange(h)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "# Plot the surface.\n",
    "H = 1\n",
    "surf = ax.plot_surface(X, Y, np.clip(np.abs(K), 0, H), cmap=cm.coolwarm,\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "# Customize the z axis.\n",
    "#ax.set_zlim(0, H + H/20)\n",
    "#ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "#ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "#fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уточнение искажающего оператора\n",
    "$$\\varepsilon = ||\\tilde{I}\\oplus\\tilde{h}-I_0|| \\to \\min_{(x,y)}$$\n",
    "Пусть $$\\tilde{I}\\oplus(\\tilde{h}+\\tilde{dh})=I_0$$\n",
    "Тогда $$\\tilde{I}\\oplus\\tilde{dh}=I_0-\\tilde{I}\\oplus\\tilde{h}$$\n",
    "Получим задачу аналогичную исходной($\\tilde{I}\\oplus h +\\eta = I_0$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_diff = liftingbody - convolve2d(deconv['image'], psf, mode='same') # Утечка\n",
    "deconv_psf = richardson_lucy_matlab(img_diff, deconv['image'], iterations=iterations, eps=1e-5, dampar=s_n, useFFT=True)\n",
    "psf_new = deconv_psf['image']\n",
    "deconv_upd = richardson_lucy_matlab(lifting_blurred, psf_new, iterations=iterations, eps=1e-5, dampar=s_n, useFFT=True)\n",
    "show_results(liftingbody, lifting_blurred, deconv_upd['image'],\n",
    "             titles=['blurred', 'restored', 'restored with\\nnew psf'])\n",
    "plot_corr(iterations+1, [deconv['correlationX'], \n",
    "                         deconv['correlationY'],\n",
    "                         deconv_upd['correlationX'],\n",
    "                         deconv_upd['correlationY']], \n",
    "          legend=['row correlation', 'column correlation', 'row correlateion(new psf)', 'column correlation(new psf)'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "951px",
    "left": "0px",
    "right": "1857.18px",
    "top": "111px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
